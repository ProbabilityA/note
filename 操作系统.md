## 操作系统内核
### 用户态和内核态
+ 与硬件紧密相关的模块安排在紧靠硬件的软件层并常驻内存，即为 OS 内核
+ 划分目的
    - 保护内核，防止遭到其他应用程序的破坏
    - 提高 OS 的运行效率
+ 状态：内核态和用户态
    - 内核态：权限较高，能执行一切指令
    - 用户态：权限较低，一般情况下应用程序只能在用户态执行

### 操作系统内核功能
+ 基本功能	
    - 中断处理
    - 时钟管理
    - 原语操作：原语由若干指令组成，执行过程中不允许被中断
+ 资源管理功能
    - 进程管理
    - 存储器管理
    - 设备管理

## 进程与线程
### 概念
+ 进程是对运行时程序的封装，是系统进行**资源分配**和**调度**的基本单位，**实现了操作系统的并发**
    - 程序段
    - 数据段
    - PCB （进程控制块）
        * 进程标识符
        * 通用寄存器、指令计数器等寄存器内容
        * 进程调度信息如进程状态、进程优先级等
        * 进程控制信息如程序的内存的首地址，进程分配的资源，指向下一个 PCB 的指针等
+ 线程是最小的执行单元，是 **CPU 调度和分派的基本单位**，共享所属进程的内存空间，**实现了进程内部的并发**
+ 区别
    - 进程是资源分配的最小单位，线程是 CPU 调度的最小单位
    - 进程拥有独立的内存单元，而多个线程共享所属进程的内存单元
    - 创建或撤销进程时，系统都要为之分配或回收资源，因此创建或撤销进程的开销远大于创建或撤销线程时的开销
    - 进程切换涉及到当前进程 CPU 环境的保存以及被调度运行的进程的 CPU 环境的设置，而线程切换只须保存和设置少量寄存器的内容

### Linux 进程 & 线程
+ 进程就是出于执行期的程序，线程是进程中活动的对象，每个线程拥有一个独立的计数器、进程栈和进程寄存器，与进程共享内存地址空间、打开的文件和其他资源等
+ Linux 进程的创建是调用`**fork()**`的结果，该系统调用通过**复制**一个现有的进程来创建一个全新的进程，调用结束后父进程在调用点恢复执行，子进程开始执行，`**exec()**`函数负责读取可执行文件并将其**载入地址空间**开始运行
+ 内核把进程的列表存放在双向循环链表`task list`（任务队列）中，链表中的每一项都是`task_struct`（进程描述符，包含打开的文件、进程的地址空间、挂起的信号、进程的状态、pid 等）
+ 系统中允许同时存在的进程的最大数目受**进程标识值 PID 限制**
+ Linux 进程的 5 个状态
    - 运行：**正在执行**、或者在运行队列**等待执行**（对应**就绪**和**运行**两种状态）
    - 可中断：**睡眠、阻塞**，但是可以接收信号并随时准备投入运行
    - 不可中断：不响应任何信号
    - `_TASK_TRACED`：被其他进程跟踪、调试
    - `_TASK_STOPPED`：进程停止执行，比如收到`SIGSTOP`等信号的时候
+ 所有 Linux 进程都是 PID 为 1 的 init 进程的后代
+ **在 Linux 中线程被当作进程来实现**，也拥有`task_struct`，仅仅被视为一个与其他进程共享某些资源的进程
+ 进程的终结
    - 自身引起：`exit()`系统调用（C 语言编译器会在`main()`返回点后面放置`exit()`）
    - 接收到信号
    - 发生异常被动终结
+ 进程终结后`task_struct`、内核栈和`thread_info`不会被立刻回收，会先通知父进程



> 如何创建进程
>

所有的 `Linux` 进程都是 `pid` 为 `1` 的 `init` 进程的子进程。

**通过父进程进行 **`**fork()**`** 操作获得子进程**。



> 如果父进程退出了，子进程会如何？
>

+  子进程退出的时候，**父进程能够收到子进程退出的信号**，便于管理； 
+  一般情况下，父进程退出后，是**不会通知子进程**的，这个时候子进程会成为**孤儿进程**，可能会被别的进程收养，在所有进程退出后，最终**被 **`**init**`** 进程收养**； 
    - 子进程可以**通过调用 **`**prctl(PR_GET_PDEATHSIG)**` 让**父进程退出时收到信号**，但是该函数并非所有系统都支持；
    - 可以通过与父进程**建立无名管道**，通过管道检测来判断父进程状态是否正常；



> 如何辨别父子进程？
>

`fork()` 操作会开启一个新进程，把父进程的所有值都复制到子进程中，只有少数值与原来的进程的值不同，甚至子进程起始运行的函数位置就是 `fork()` 函数的返回。

+ `fork` 函数会在父进程返回子进程的 `pid`；
+ `fork` 函数会在子进程返回 `0`；
+ `fork` 函数执行失败返回负值，可能原因：**进程数量上限**或**内存不足**；



> `fork` 函数发生什么？
>

`fork` 函数调用会开启一个新的进程，新进程拥有独立的虚拟内存空间，但是它的代码段、数据段，甚至堆栈都是指向父进程的物理空间，这是为了效率考虑。

在 `Linux` 中采用了"写时复制"的技术，在父进程对段进行更改之前，会把这个段重新复制一份到别的物理地址空间，防止子进程运行出错。

另外，`fork` 执行后，内核会把子进程的 `task` 放到队列的前面，防止父进程先执行然后做了修改导致写时复制，而后子进程又执行了 `exec` 系统调用，导致无意义的复制而使得效率下降。

### 特征
+ 动态性：程序是静态的，进程是动态的
+ 并发性：多个进程实体同存于内存，并且在一段时间内并发运行
+ 独立性：进程实体是能独立运行、获得资源、接受调度的基本单位
+ 异步性：进程按照各自独立的不可预知的速度推进，因此推进结果不可再现

### 状态
+ 创建
+ 就绪
+ 运行
+ 阻塞
+ 退出
+ （引入挂起将增加多两个状态）

![](https://cdn.nlark.com/yuque/0/2022/png/1732113/1642409891601-64d7b264-dc6b-4608-b60c-979dfd852e15.png)

### 互斥与同步
+ 互斥：某一资源同时只允许一个访问者对其进行访问
+ 同步：在互斥的基础上，通过其他机制实现对资源的**有序访问**
    - 同步机制需要遵守的原则
        * 空闲让进
        * 忙则等待
        * 有限等待（避免“死等”）
        * 让权等待：进程不能进入临界区时需要释放处理机，避免“忙等”

### 线程同步方式
+ 临界区
    - 对多线程串行化，任何时候只允许一个线程进入临界区，访问资源的程序片段称为临界区
    - 当有线程在临界区内时，其他线程进入临界区段必须等待
+ 互斥量（互斥）
    - 定义一个互斥量，协调线程对一个共享资源的单独访问。互斥量只有一个，只有拥有互斥量的线程才有权限访问共享资源。互斥量不仅能实现同一个应用程序的资源安全共享，还能实现不同应用程序的公共资源的安全共享
+ 信号量（限流）
    - 为控制一个具有有限数量的用户资源而设计，允许多个线程在同一时刻访问同一资源，但一般有最大数量限制
+ 事件
    - 用来通知线程有一些事件已发生，从而启动后继任务的开始

### 硬件同步机制
+ 需要进入临界区的进程，执行以下步骤
    1. 进行锁测试，判断锁是开还是关闭
    2. 锁关闭时，需要等待，直到锁打开
    3. 锁打开时，允许当前进程进入临界区并将锁关闭，防止其他进程进入临界区
+ **为了防止多个进程测试到锁打开，锁测试和关锁操作必须是连续的**

#### 关中断
+ 进入锁测试前关闭中断，CPU 不响应中断，不会引发调度，不会发生进程或线程切换，则可以防止多个进程测试锁
+ 缺点
    - 关中断会限制处理器并发执行程序的能力，影响系统效率
    - 不适用于多 CPU 的情况，因为在一个处理器关中断无法保证代码在其他处理器上不会执行

#### Test-And-Set 指令
+ 尝试将锁设置为 true，并返回原来锁的状态，当返回 false 才能进入临界区

#### Swap指令
+ 类似 Test-And-Set 指令
+ 缺点：临界资源忙碌时，其他进程会一直进行测试，处于“忙等”状态，不符合“让权等待”

### 信号量机制
`wait(S)`和`signal(S)`

#### 记录型信号量
```c
typedef struct{
	int value;
	struct process_control_block * list;
} semaphore;

// P操作
wait(semaphore *S)
{
	S->value --;
	if(S->Value < 0){
		block( S->list );
	}
}
signal(semaphore *S){
	S->value++;
	if(S->value <= 0){
		wakeup(S->list);
	}
}
```

#### And 型信号量
一次分配和释放所有资源，`Swait`和`Ssignal`

#### 信号量集
```c
// Swait(S, t, d)表示
// 资源 S 的分配下限为 t,即当 S < t 时，不予分配
// 进程对资源 S 的需求量为 d，即执行 Swait 时，内部执行 S = S - d，不再是 S = S - 1
Swait(S1, t1, d1, S2, t2, d2...);
Ssignal(S1, t1, d1, S2, t2, d2...);

// 一般信号量集的情况
Swait(S,1,1)：与一般记录型信号量一致
Swait(S,1,0)：一个可控开关，资源数大于等于 1 时，允许进程进入临界区，进入后资源数不会变 
```

### 管程机制
+ 引入背景：使用信号量机制需要每个访问临界资源的进程都自备PV操作，使得大量同步操作分布在各个进程中，造成系统管理麻烦，使用不当还可能导致系统死锁
+ 定义：一个管程定义了一个数据结构和能为并发所执行在该数据结构上的一组操作，这组操作能同步进程和改变管程中的数据，简化了程序设计
+ 做法：
    - 进程通过调用管程来对资源进行更改，而管程中每次只能有一个进程进入
    - 管程中使用多个条件队列来放置阻塞的进程

### 作业 & 进程调度算法
1. 先来先服务（FCFS）
2. 短作业优先（SJF）
3. 高响应比优先算法（HRRN）
    1. 响应比 = （作业处理时间 + 作业等待时间） / （作业处理时间）
4. 时间片轮转算法（RR）
5. 优先级调度算法（优先级越高越先调度）
6. 多级反馈队列调度算法
    1. 结合了优先级和时间片两种思想，设置多个队列，优先级越高的队列时间片越短

### Linux 的进程调度
+ 概念
    - I/O 消耗型进程：图形桌面程序等
    - 处理器消耗型进程：大量数学计算的程序，MATLAB 等
    - 调度策略需要在**两个矛盾的目标中间寻找平衡**：进程响应迅速（响应时间短）和最大系统利用率（高吞吐量）
    - Linux 进程优先级
        * `nice`值，[-20, 19]，**越大**的`nice`值优先级**越低**
        * 实时优先级，[0, 99]，越大优先级越高，可配置
    - Linux 中任何进程所获得的处理器时间是由**它自己**和**其他所有可运行进程**的`nice`值的**相对差值**决定的，`nice`值对应处理器的使用时间比
    - 上下文切换：从一个可执行进程切换到另一个可执行进程
+ `O(1)`调度器
    - 多处理器环境下表现出色，但是在有**交互程序**需要运行的桌面系统**表现不佳**，**缺少交互进程**
    - 长度 140 （对应 140 种优先级）的 array，每个位置放置一个 FIFO 的队列，每次出列和入列都是`O(1)`
    - 怎么找到最高优先级下可执行的进程？`<font style="color:rgb(18, 18, 18);">bitarray</font>`，对应优先级里有进程就对应的 bit 为 1
+ **CFS 调度器**（完全公平调度器）
    - 使用红黑树实现，调度效率为`O(logn)`
    - 调度策略（选哪个进程执行）——**机会平等，时间差异**
        * 引入**虚拟运行时间**`vruntime`，**调度器总是选**`vruntime`**最小的进程执行，从树的根节点沿着左边的子节点向下找，一直到叶子节点**
        * **机会平等体现在**调度器总是以`vruntime`为衡量，选`vruntime`最小的进程进行调度
        * `vruntime = 实际运行时间 * 1024 / 进程权重`
        * **时间差异体现在**由上述公式可得两个进程的`vruntime`获得相同增量，进程权重大的实际运行时间更多
    - 执行时间（被调度的进程一次执行多久）
        * `实际运行时间 = 调度周期 * 进程权重 / 全部进程权重之和`
    - 新进程的`vruntime`是不是 0？
        * 不是，如果是 0 那么在相当长一段时间内都会选择调度这个新进程，使得老进程饿死，会以当前 CPU 的调度队列的`min_vruntime`为初始值
    - 休眠进程唤醒后`vruntime`保持不变嘛？
        * 不是，原因同上，但会以`min_vruntime`对这个进程的`vruntime`进行一定的补偿
    - 进程占用的时间片可以无限小嘛？
        * 为避免频繁线程切换，CFS 设定了进程占用 CPU 的最小时间值
    - 进程迁移到别的 CPU 运行，`vruntime`的变化？
        * 减去原来的 CPU 的运行队列的`min_vruntime`，然后加上新的 CPU 的运行队列的`min_vruntime`

### Linux 的实时调度
+ `SCHED_NORMAL`是普通的、非实时调度策略
+ `SCHED_FIFO`
    - 先进先出，进程会一直执行到被阻塞或显式地释放处理器（如`Thread.yield()`），不基于时间片，但可抢占
+ `SCHED_RR`
    - 带有时间片的`SCHED_FIFO`

## 进程通信
1. （匿名）管道
+ 特点
    - 半双工，数据只能往一个方向流动，如果要双方通信需要两个管道
    - 用于父子进程或兄弟进程（有亲缘关系的进程）
    - 实质是内核缓冲区，内容存于内存中，读和写的位置自动增长，一个数据只能被读一次
+ 局限性
    - 只能用于具有亲缘关系的进程之间
    - 只支持单向数据流
    - 没有名字
    - 缓冲区容量有限
2. 有名管道
+ 特点
    - 提供了一个路径名，名字存在于文件系统中，内容仍存于内存中
    - 任意进程之间只要可以访问到路径名对应的路径就可以借助有名管道通信
+ 局限性
    - 半双工
    - 缓冲区容量有限
3. 信号量
+ 是一个计数器，用于实现进程间的同步操作
+ 创建信号量，指定其初始值
+ 等待一个信号量，如果信号量小于 0 则阻塞，也就是 P 操作
+ 挂出一个信号量，将信号量的值加 1，也就是 V 操作
4. 信号
+ 特点
    - 无需知道进程的状态就可以对其发送信号
+ 常见信号
    - `SIGINT`程序终止信号`Ctrl + C`
    - `SIGQUIT`程序退出信号`Ctrl + \`
    - `SIGKILL`用户终止进程执行信号`kill -9`
    - `SIGTERM`结束进程信号`kill`
5. 消息队列
+ 特点
    - 采用链表实现，存于内核中，由消息队列标识符标识
    - 可以随机读取，不用按照先进先出读取
    - 只有在内核重启或人工删除，消息才会被删除
6. 共享内存
+ 特点
    - 多个进程可同时读写同一块内存空间，是效率最高的进程通信方式
    - 进程可以将这块内存空间映射到自己的私有地址空间，直接读写
    - 需要依靠同步机制（如信号量）来实现进程间的同步和互斥操作
7. 套接字
+ 特点
    - 可以在本机实现进程通信，也可以实现网络上不同主机的进程通信
    - 套接字是支持 TCP/IP 的网络通信的基本操作单元，是进程之间进行双向通信的端点

## 中断
+ 中断

指发生了某些需要处理器注意的事件，处理器暂停正在运行的程序，转到中断服务程序，处理完之后又恢复原来程序的运行。

+ 软中断

由一条 CPU 指令引发的中断，CPU 从用户态切换到内核态，一般用来实现系统调用。

+ 硬中断

硬件引发的中断，例如鼠标和键盘的点击

## 死锁
### 概念
如果一组进程中的每一个进程都在等待仅能由该组进程中的其他进程引发的事件，那么该组进程是死锁的

### 原因
+ 竞争不可抢占性资源
+ 竞争可消耗资源
+ 进程推进顺序不当

### 必要条件
+ 互斥条件：临界资源是独占资源
+ 请求和保持条件：进程等待时不释放已持有的临界资源
+ 不可抢占条件：临界资源只能由持有进程自己释放，不可让其他进程抢占
+ 循环等待条件：存在循环等待链，每一个进程都在等待下一个进程释放其持有的资源

### 处理死锁
+ 预防：通过限制条件去破坏死锁的四个必要条件
+ 避免：资源分配的过程中防止系统进入不安全状态（银行家算法）
+ 检测：及时检测是否发生死锁
    - 画资源分配图，如果出现环路则说明出现死锁
+ 解除：撤销死锁进程，回收其资源并重新分配资源

## 存储器管理
### 层次结构
![](https://cdn.nlark.com/yuque/0/2020/png/427474/1604031927161-12377d32-9f6c-4c0e-b24f-1eb23abe9c42.png)

### 程序装入
+ 编译 -> 链接（与库函数链接） -> 装入内存
+ 程序装入
    - 绝对装入：程序的项目物理地址 = 逻辑地址，前提是编译程序必须知道内存的当前空闲地址部分和其地址，适用于单道程序环境
    - 可重定位装入（静态地址重定位）：程序开始运行前，程序中指令和数据的各个地址进行重定位，即**虚拟地址到内存地址**的映射
        * ![](https://cdn.nlark.com/yuque/0/2022/jpeg/1732113/1643785431232-9801bad2-3b9b-4e46-994d-1869710435e2.jpeg)
        * 装入内存空间后，原本指令上的地址也需要改变，如上图 LOAD 1, 2500 应改为 LOAD 1, 12500
        * 缺点：不允许程序在运行时在内存中移动位置
    - 动态地址重定位
        * 需要多一个 重定位寄存器 支持，在程序执行时才进行地址变换
        * 优点是可以在程序运行时在内存中移动位置，缺点是需要硬件支持

### 固定分区分配
+ 单一连续分配：整个内存空间由一个程序独占
+ 固定分区分配：将内存空间划分为若干大小固定的区域

### 动态分区分配
+ 数据结构
    - 空闲分区表
    - 空闲分区链
+ 分配算法
    - 顺序搜索
        * 首次适应算法：从链表首部开始查找，直到找到大小满足要求的分区
            + 低址部分不断划分，留下很多碎片
        * 循环首次适应算法：从上次找到大小满足要求的分区的位置开始查找
            + 缺乏大分区
        * 最佳适应算法：链表按照容量大小递增排序，找到满足要求的最小空闲分区
            + 碎片较多
        * 最坏适应算法：链表按照容量大小递减排序
            + 查找效率高，只需要判断第一个分区是否满足要求
            + 产生碎片的可能性小
    - 索引搜索
        * Buddy 系统
+ 分配操作
    - 分配内存
        * 找到一个大小合适的空闲分区
        * 判断分配完的碎片分区大小是否过小，如果过小则不进行切分，如果较大则切分出大小合适的分区
    - 回收内存
        * 判断能否与前后的（空闲）分区进行合并

### Linux 内存管理
+ 内核把物理**页**作为内存管理的基本单位，一般为 **4KB**，由体系结构决定
    - 结构体`page`表示每个物理页
        * flags 域存放页的状态，比如是否为脏页等
        * _count 域存放页的引用计数
        * virtual 域是页的虚拟地址
+ 内核使用区对具有相似特性的页进行分组
    - `ZONE_DMA`执行 DMA 操作
    - `ZONE_DMA32`只能被 32 位设备执行 DMA 操作
    - `ZONE_NORMAL`包含的都是能正常映射的页
    - `ZONE_HIGHEM`高端内存，其中的页不能永久地映射到内核地址空间

### Linux 进程地址空间
+ 进程地址空间由进程可寻址的虚拟内存组成，进程拥有的地址空间可以远大于系统物理内存
+ 内存描述符`mm_struct`
    - `mm_users` 正在使用该地址的进程数目，比如线程共享该地址空间
    - `mmap` 该地址空间中的全部内存区域，以链表的形式，利于简单地遍历
    - `mm_rb` 该地址空间中全部的内存区域，以红黑树的形式，利于搜索指定元素
+ `mmap()` / `do_mmap()`：创建地址空间
    - `unsigned long do_mmap(...)`会将一个地址区间加入到进程的地址空间中
        * 该函数映射由`struct file *file`指定的文件，从文件偏移处`unsigned long offset`开始，长度为`unsigned long len`的字节范围内的数据
    - 实现映射关系后，进程就可以采用指针的方式读写操作这一段内存，系统会自动回写脏页面到对应的文件磁盘上，即完成了对文件的操作而不必再调用 read, write 等系统调用函数
    - `**mmap()**`**过程**
        * 进程启动映射过程，在地址空间中为映射创建虚拟映射区域
        * 调用内核`mmap()`，通过输入参数指定的文件、文件偏移处和长度，将虚拟映射区域和文件的物理地址映射起来，此时文件数据还没有被拷贝到主存
        * 进程发起对这片映射空间的读写，引发缺页中断，实现文件内容到物理内存的拷贝
        * 如果发生了写操作，系统会在一定时间后将脏页刷新回对应的物理地址，也可以通过调用`msync()`强制同步刷新
+ `mmap`与常规读写（`read()` / `write()`）的区别
    - 常规读写会先将数据拷贝到内核页缓存中，由于页缓存处在内核空间，不能被用户进程直接寻址，所以还需要将页缓存中数据页再次拷贝到内存对应的用户空间中，**一共发生了两次数据拷贝**
    - 而`mmap`先建立虚拟地址到文件物理地址的映射，没有发生数据拷贝，在读写虚拟地址时发生缺页中断，只需要一次数据拷贝，**省去了内核空间和用户空间的数据交换这一过程**
+ 页表
    - 应用程序操作的对象是映射到物理内存上的虚拟内存，处理器在操作物理内存时需要先将进程的虚拟地址转换为物理地址，地址的转换工作需要通过查询页表完成
    - **页面置换算法**
        * 最佳置换算法`OPT`：很难实现，因为难以估计未来哪个页面使用的最少
        * 先进先出算法`FIFO`：置换在内存中驻留时间最久的页面，可能会淘汰经常使用的页面
        * 最近最久未使用算法`LRU Last Recently Used`：置换最长时间未访问过的页面
    - Linux 采用改进的 LRU 算法，两级 LRU 算法

### Linux 内存分配
+ `alloc_pages(...)` / `__get_free_pages(...)`（属于 Buddy 系统）
    - 分配指定数量的**页**
+ `kmalloc()` / `kfree()`
    - **内核分配用的比较多，工作于 slab 分配器上**
    - 可以分配以**字节**为单位的一块内核内存
    - 分配到的内存物理地址是连续的
    - **应用场景：硬件设备需要用到的内存区（必须是连续的）**
+ `vmalloc()` / `vfree()`
    - 分配到的内存虚拟地址是连续的，**物理地址不一定是连续的**
    - 需要建立页表项进行映射，会有一定性能损失
    - **应用场景：需要大块内存**
+ slab 层——通用数据结构缓存层
    - 内核经常使用`kmalloc()`分配和释放数据结构，slab 分配器会缓存它们
    - 如果要创建和撤销很多大的数据结构，考虑建立 slab 高速缓存

![](https://cdn.nlark.com/yuque/0/2022/png/1732113/1644215946066-92b64cb7-2ef7-49ef-8bdd-e4f3ef7f469a.png)

+ Buddy 系统
    - 将空闲内存分为 11 个链表，每个链表分别存储 1、2、4、8、16...1024 个连续页面的块，最大可以申请 1024 个页，也就对应 4MB 大小的连续内存
    - 这样做的好处是，所有正整数都可以由 2^n 的和组成
    - ![](https://cdn.nlark.com/yuque/0/2022/png/1732113/1644216464987-27bf56dc-c52d-4d38-a58b-1267dd335ef7.png)
    - 由于在拆分的过程中会导致碎片化的现象，因此可以通过虚拟内存构建页表将不连续的物理地址映射到连续的虚拟地址上，而硬件需要的连续物理内存可以通过 CMA 机制预留

### 虚拟文件系统 VFS
+ 在底层文件系统接口上建立抽象层，以支持各种文件系统的读写操作
+ 用户空间调用`ret = write(fd, buf, len)`，请求将 buf 指针指向的长度为 len 字节的数据写入文件描述符 fd 对应的文件
    - 该调用首先被 VFS 层的`sys_write()`处理，此函数会找到 fd 所在的文件系统实际给出的是哪个写操作
    - 然后再执行实际文件系统的写操作
    - 数据通过该操作写入介质

![](https://cdn.nlark.com/yuque/0/2022/png/1732113/1643994747701-72cd8064-2ce7-4540-824d-8515242c9a4a.png)

+ 4 种数据结构
    - 超级块对象：记录文件系统信息
    - 索引节点对象：内核中用 inode 结构表示具体文件，用 file 结构来表示打开的文件描述符
    - 目录项：路径的一个组成部分（但 Linux 把目录当作文件对待）
    - 文件对象：表示进程已打开的文件

## I/O
### Unix 的五种 I/O 模型概念
+ 操作系统内核能直接与存放数据的物理介质交互，因此数据往往需要先通过操作系统内核复制到内核态，再由操作系统将数据从内核复制到用户访问得到的用户空间

#### 阻塞式 I/O（Java BIO 对应）
+ 用户空间发起调用，线程一直处于等待状态，数据先从物理介质加载到内核态，再从内核态加载到用户态

![](https://cdn.nlark.com/yuque/0/2022/jpeg/1732113/1644043860531-9cd018c0-adaf-483a-903b-ad8249e44d52.jpeg)

#### 非阻塞 I/O
+ 数据从物理介质加载到内核态这一过程是非阻塞的，用户线程通过轮询判断数据是否已加载到内核态

![](https://cdn.nlark.com/yuque/0/2022/jpeg/1732113/1644043959982-714adc91-8a83-4150-b58f-833f58928fad.jpeg)

#### I/O 多路复用（Java NIO 对应）
+ 用户进程通过 select / epoll ，阻塞式的查看内核数据是否准备完毕，当内核数据加载完成之后，调用 recvfrom，将内核态的数据加载到用户态

这里看起来第一步和第二步都是阻塞式操作，但 select 可以在极小代价的情况下，同时处理**多个**文件句柄（包括socket）

+ **I/O 多路复用的优势在于可以同时处理更多的连接，而不是对单个连接的处理速度更快**
    - 如果处理的连接数不是很高的话，使用 select / epoll 的 web server 不一定比使用多线程和阻塞式 I/O 的 web server 性能更好，可能延迟还更大

![](https://cdn.nlark.com/yuque/0/2022/jpeg/1732113/1644044102531-5bde1d36-ea06-4e35-90a9-fa5116a285f6.jpeg)

##### select
+ 跨平台
+ 对文件描述符 fd 有数量限制，Linux 下为 1024，可以修改（通过重新编译内核），但是太高效率会下降

##### poll
+ 无数量限制（但数量过多会影响效率），基于链表实现
+ select 和 poll 需要每次传入监听的 fd，并在返回后，通过遍历文件描述符来获取已经就绪的文件

##### epoll
+ Linux 对 poll 的改进版本，基于红黑树实现
+ epoll 对象在内核中被创建，维护了一个事件表，不需要每次传入 fd
+ 基于事件队列，返回后不需要遍历所有 fd

#### 信号驱动 I/O
+ 向系统注册回调函数，数据加载到内核态后会通过信号通知用户进程，用户进程收到信号后阻塞式地调用 recvfrom，将数据从内核态加载到用户态

![](https://cdn.nlark.com/yuque/0/2022/jpeg/1732113/1644044145632-203d1be5-ce62-4292-923b-791a523a15b3.jpeg)

#### 异步 I/O（Windows 中的 Java AIO 对应）
+ 以上四步，数据从内核态加载到用户态都是阻塞的
+ 此模型中用户进程通过`aio_read`注册一个系统调用，内核态在将数据复制到用户态后通过信号通知用户进程

![](https://cdn.nlark.com/yuque/0/2022/jpeg/1732113/1644044245160-916d3205-5cfd-4438-a60d-4b02c4264494.jpeg)

### DMA 技术
+ Direct Memory Access 直接内存访问，在进行 I/O 设备和内存的数据传输的时候将数据搬运的工作交给 DMA 控制器，CPU 在这个时候可以处理别的事情

![](https://cdn.nlark.com/yuque/0/2022/png/1732113/1644068901284-d1c34cfb-d983-450e-8858-a234a057f6f4.png)

### 文件传输
#### 传统的文件传输过程
![](https://cdn.nlark.com/yuque/0/2022/png/1732113/1644068969591-71c2d6d5-8eeb-4fcb-b8eb-58f5e765ad31.png)

+ 经历 4 次内核态和用户态的上下文切换
+ 经历 4 次数据搬运
    - 磁盘文件 -> 内核缓冲区（DMA 搬运）
    - 内核缓冲区 -> 用户缓冲区（CPU 搬运）
    - 用户缓冲区 -> socket 缓冲区（CPU 搬运）
    - socket 缓冲区 -> 网卡（DMA 搬运）
+ **因此优化的思路是**
    - **减少用户态和内核态之间的上下文切换**
    - **减少内存拷贝的次数**

#### mmap + write
+ mmap 建立的虚拟映射可以减少内核缓冲区到用户缓冲区的数据拷贝
+ 即减少为 3 次数据拷贝，但**仍需 4 次上下文切换**

![](https://cdn.nlark.com/yuque/0/2022/png/1732113/1644069267669-96a9d2ee-7d55-4e47-a3fe-be1a6fc5ffd7.png)

#### sendfile
+ 通过一次系统调用替代`mmap`和`write`两次系统调用，减少了 2 次上下文切换
+ 需要 2 次上下文切换和 3 次数据拷贝，即数据从磁盘文件经 DMA 拷贝至内核缓冲区，再到 socket 缓冲区，再到网卡

![](https://cdn.nlark.com/yuque/0/2022/png/1732113/1644069306816-9fc1eab9-6e7d-49c4-8b6f-6f5c450a10d2.png)

#### sendfile（支持 SG-DMA 的网卡）
+ 通过 DMA 将数据从磁盘介质拷贝到内核缓冲区
+ 将缓冲区描述符和数据长度传到 socket 缓冲区，由网卡的 SG-DMA 控制器直接从内核缓冲区拷贝数据到网卡，减少了内核缓冲区到 socket 缓冲区的数据拷贝（即 2 次数据拷贝）

![](https://cdn.nlark.com/yuque/0/2022/png/1732113/1644069691502-981d89ea-fc52-49d0-bbff-db06a116efbe.png)

+ 这属于真正的零拷贝，即直接将数据从文件系统拷贝到网络接口，不需要经历将数据从内核空间拷贝到用户空间这一过程

#### <font style="color:rgb(49, 70, 89);">splice</font>
+ sendfile 只适用于将数据从文件拷贝到 socket 套接字上，同时需要硬件的支持
+ splice 实现了两个文件描述符之间的数据零拷贝
    - 用户调用`splice()`，上下文从用户态切换到内核态
    - DMA 控制器复制数据到内核缓冲区
    - CPU 建立内核缓冲区到 socket 缓冲区的管道
    - DMA 从 socket 缓冲区复制数据到网卡
    - `splice()`返回，上下文从内核态切换回用户态

![](https://cdn.nlark.com/yuque/0/2022/jpeg/1732113/1644070080349-3aa77dba-fa32-44d4-a340-b7780ae418ca.jpeg)



### Linux I/O 调度
+ Linus 电梯
+ 最终期限 I/O 调度
    - 每个请求都有一个超时时间，超时请求优先处理
+ 预测 I/O 调度
    - 将一些小写入流合并成一个大写入流，用写入延时换取最大的写入吞吐量
+ CFQ 完全公平排队调度（目前默认）
    - 适合桌面环境，试图均匀分布 I/O 带宽的访问

